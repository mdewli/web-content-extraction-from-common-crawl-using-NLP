{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gdrt0iPOOdF",
        "outputId": "0f9ca0e9-b620-4889-a622-02a3d36fd2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ-OOkv8OrVD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "1WZKbnZVOrXi",
        "outputId": "33f11aa6-e655-45bb-95e5-18c99309c112"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 url  \\\n",
              "0  https://www.pulse.ng/sports/opinion/3-things-l...   \n",
              "1  https://sportspyder.com/cf/florida-gators-foot...   \n",
              "2  https://www.homify.hk/professionals/kitchen-pl...   \n",
              "3  https://wyborcza.pl/7,75399,28495755,100-dni-w...   \n",
              "4  https://www.st.nu/2022-06-03/byggforetagen-vil...   \n",
              "\n",
              "                                                html  \\\n",
              "0  \\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html lang=\"en\">\\n\\...   \n",
              "1  <!doctype html><html lang=\"en\"><head><meta cha...   \n",
              "2  <!DOCTYPE html>\\n<html class=\"-logged-out- -lo...   \n",
              "3  \\n<!DOCTYPE html>\\n<html>\\n<head>\\n<meta chars...   \n",
              "4  <!DOCTYPE html><html lang=\"sv\" id=\"root-elemen...   \n",
              "\n",
              "                                                text encoding  lang language  \\\n",
              "0  CDATA ringDataLayer context variant accelerato...    utf-8    en       en   \n",
              "1  Sports News Tweets Rumors and Articles SportSp...    UTF-8    en       en   \n",
              "2  function w d s l i wl wl  wl push gtm start ne...    utf-8    en       en   \n",
              "3  Wyborcza pl body font family Arial sans serif ...    UTF-8  None       en   \n",
              "4  window hdsconfig androidAppPackage se mittmedi...    utf-8    sv       sv   \n",
              "\n",
              "   num_words                                              title  \n",
              "0       4797  3 things learnt from Jose Peseiro's second con...  \n",
              "1       1611  Sports News, Tweets, Rumors and Articles | Spo...  \n",
              "2       1334  Find the right Kitchen Planners in İstanbul | ...  \n",
              "3        689                                        Wyborcza.pl  \n",
              "4       2956  Byggföretagen vill mörka lönedumpning – Sundsv...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59195a69-5ef4-4bbf-b0ec-7c47dbfb1d42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>html</th>\n",
              "      <th>text</th>\n",
              "      <th>encoding</th>\n",
              "      <th>lang</th>\n",
              "      <th>language</th>\n",
              "      <th>num_words</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.pulse.ng/sports/opinion/3-things-l...</td>\n",
              "      <td>\\n\\n\\n\\n\\n&lt;!DOCTYPE html&gt;\\n&lt;html lang=\"en\"&gt;\\n\\...</td>\n",
              "      <td>CDATA ringDataLayer context variant accelerato...</td>\n",
              "      <td>utf-8</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>4797</td>\n",
              "      <td>3 things learnt from Jose Peseiro's second con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://sportspyder.com/cf/florida-gators-foot...</td>\n",
              "      <td>&lt;!doctype html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;meta cha...</td>\n",
              "      <td>Sports News Tweets Rumors and Articles SportSp...</td>\n",
              "      <td>UTF-8</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>1611</td>\n",
              "      <td>Sports News, Tweets, Rumors and Articles | Spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.homify.hk/professionals/kitchen-pl...</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html class=\"-logged-out- -lo...</td>\n",
              "      <td>function w d s l i wl wl  wl push gtm start ne...</td>\n",
              "      <td>utf-8</td>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>1334</td>\n",
              "      <td>Find the right Kitchen Planners in İstanbul | ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://wyborcza.pl/7,75399,28495755,100-dni-w...</td>\n",
              "      <td>\\n&lt;!DOCTYPE html&gt;\\n&lt;html&gt;\\n&lt;head&gt;\\n&lt;meta chars...</td>\n",
              "      <td>Wyborcza pl body font family Arial sans serif ...</td>\n",
              "      <td>UTF-8</td>\n",
              "      <td>None</td>\n",
              "      <td>en</td>\n",
              "      <td>689</td>\n",
              "      <td>Wyborcza.pl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.st.nu/2022-06-03/byggforetagen-vil...</td>\n",
              "      <td>&lt;!DOCTYPE html&gt;&lt;html lang=\"sv\" id=\"root-elemen...</td>\n",
              "      <td>window hdsconfig androidAppPackage se mittmedi...</td>\n",
              "      <td>utf-8</td>\n",
              "      <td>sv</td>\n",
              "      <td>sv</td>\n",
              "      <td>2956</td>\n",
              "      <td>Byggföretagen vill mörka lönedumpning – Sundsv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59195a69-5ef4-4bbf-b0ec-7c47dbfb1d42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59195a69-5ef4-4bbf-b0ec-7c47dbfb1d42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59195a69-5ef4-4bbf-b0ec-7c47dbfb1d42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df = pd.read_parquet('/content/gdrive/MyDrive/Common_Crawl/data/dataset.parquet')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THIMlboEOraR",
        "outputId": "2eed91a5-5636-48c3-8428-29e775a7db59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['url', 'html', 'text', 'encoding', 'lang', 'language', 'num_words',\n",
              "       'title'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import ElectraTokenizer, TFElectraForSequenceClassification\n",
        "from transformers import XLMRobertaTokenizer, TFXLMRobertaForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "-JjhqWY4woma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmA6say5Orig",
        "outputId": "6353c423-1d23-4074-cdd2-7f65472ec393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]Some layers from the model checkpoint at google/electra-small-generator were not used when initializing TFElectraForSequenceClassification: ['activation', 'generator_predictions', 'generator_lm_head']\n",
            "- This IS expected if you are initializing TFElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "475/475 [==============================] - 15s 26ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [42:09<1:24:18, 2529.37s/it]All model checkpoint layers were used when initializing TFBartForSequenceClassification.\n",
            "\n",
            "Some layers of TFBartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239/475 [==============>...............] - ETA: 9s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [1:38:56<3:17:52, 5936.35s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e4e3713e50c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'tf_bart_for_sequence_classification_1/model/decoder/layers.0/encoder_attn/Softmax' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-22-e4e3713e50c5>\", line 59, in <module>\n      preds = np.argmax(model.predict(test_dataset.batch(16)).logits, axis=-1)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2350, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2137, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2123, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2111, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2079, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py\", line 745, in run_call_with_unpacked_inputs\n      layer_name = \"/\".join(k.name.split(\"/\")[1:])\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\", line 1542, in call\n      outputs = self.model(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py\", line 745, in run_call_with_unpacked_inputs\n      layer_name = \"/\".join(k.name.split(\"/\")[1:])\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\", line 1151, in call\n      decoder_outputs = self.decoder(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_tf_utils.py\", line 745, in run_call_with_unpacked_inputs\n      layer_name = \"/\".join(k.name.split(\"/\")[1:])\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\", line 1019, in call\n      for idx, decoder_layer in enumerate(self.layers):\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\", line 1019, in call\n      for idx, decoder_layer in enumerate(self.layers):\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\", line 1031, in call\n      hidden_states, layer_self_attn, layer_cross_attn, present_key_value = decoder_layer(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\", line 428, in call\n      if encoder_hidden_states is not None:\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\", line 433, in call\n      hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/models/bart/modeling_tf_bart.py\", line 259, in call\n      attn_weights = stable_softmax(attn_weights, axis=-1)\n    File \"/usr/local/lib/python3.8/dist-packages/transformers/tf_utils.py\", line 70, in stable_softmax\n      return tf.nn.softmax(logits=logits + 1e-9, axis=axis, name=name)\nNode: 'tf_bart_for_sequence_classification_1/model/decoder/layers.0/encoder_attn/Softmax'\nOOM when allocating tensor with shape[192,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node tf_bart_for_sequence_classification_1/model/decoder/layers.0/encoder_attn/Softmax}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_1214452]"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Import data\n",
        "def import_data(csv_file):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df['text'] = df['Title'] + ' ' + df['Description']\n",
        "    df.rename(columns={'Class Index': 'label'}, inplace=True)\n",
        "    df['label'].replace({4: 0}, inplace=True)\n",
        "    df.drop(['Title', 'Description'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "train_val_df = import_data('/content/gdrive/MyDrive/Common_Crawl/data/train.csv')\n",
        "train_df, val_df = train_test_split(train_val_df[['text', 'label']],\n",
        "                                    test_size=0.2, random_state=42)\n",
        "test_df = import_data('/content/gdrive/MyDrive/Common_Crawl/data/test.csv')\n",
        "\n",
        "# Define the pipelines for each model\n",
        "def pipeline(dataframe, pretrained_model, tokenizer):\n",
        "    inputs = tokenizer(list(dataframe['text']), truncation=True, padding=True, max_length=128)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(inputs), dataframe['label']))\n",
        "    return dataset\n",
        "\n",
        "# Define a list of models and tokenizers\n",
        "models = [('google/electra-small-generator', ElectraTokenizer),\n",
        "          ('facebook/bart-base', AutoTokenizer),\n",
        "          ('xlm-roberta-base', XLMRobertaTokenizer)]\n",
        "\n",
        "results = []  # To store the results\n",
        "\n",
        "\n",
        "# Specify the location to save the fine-tuned models\n",
        "model_dir = \"/content/gdrive/MyDrive/Common_Crawl\"\n",
        "\n",
        "# Iterate over each model\n",
        "for model_name, tokenizer_class in tqdm(models):\n",
        "    tokenizer = tokenizer_class.from_pretrained(model_name)\n",
        "    train_dataset = pipeline(train_df, model_name, tokenizer)\n",
        "    val_dataset = pipeline(val_df, model_name, tokenizer)\n",
        "    test_dataset = pipeline(test_df, model_name, tokenizer)\n",
        "\n",
        "    # Create the model\n",
        "    model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    # Train the model\n",
        "    history = model.fit(train_dataset.shuffle(1000).batch(16),\n",
        "                        epochs=5,\n",
        "                        batch_size=16,\n",
        "                        validation_data=val_dataset.batch(16),\n",
        "                        verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluate the model\n",
        "    preds = np.argmax(model.predict(test_dataset.batch(16)).logits, axis=-1)\n",
        "    precision, recall, fscore, support = score(test_df['label'], preds)\n",
        "\n",
        "    # Save the model\n",
        "    model.save_pretrained(os.path.join(model_dir, model_name))\n",
        "\n",
        "    # Store the results\n",
        "    results.append({'model_name': model_name, 'tokenizer_class': tokenizer_class.__name__,\n",
        "                    'accuracy': accuracy_score(test_df['label'], preds),\n",
        "                    'precision': precision, 'recall': recall, 'fscore': fscore, 'support': support,\n",
        "                    'time_taken': end_time - start_time})\n",
        "\n",
        "# Print the results\n",
        "for result in results:\n",
        "    print(f\"Results for {result['model_name']} ({result['tokenizer_class']})\")\n",
        "    print(f\"Accuracy: {result['accuracy']}\")\n",
        "    print(f\"Precision: {result['precision']}\")\n",
        "    print(f\"Recall: {result['recall']}\")\n",
        "    print(f\"F-score: {result['fscore']}\")\n",
        "    print(f\"Support: {result['support']}\")\n",
        "    print(f\"Time taken: {result['time_taken']} seconds\")\n",
        "    print(\"=\"*60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ex4Ufq88qXJM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}